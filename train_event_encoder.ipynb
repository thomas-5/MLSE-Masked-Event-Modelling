{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fa60393",
   "metadata": {},
   "source": [
    "# Model Training: Masked Attribute Modeling with 360 Fusion\n",
    "\n",
    "This notebook trains an **EventEncoder** using masked attribute modeling (MAM). It includes:\n",
    "1. Bucketized numerical features (already computed in preprocessing).\n",
    "2. MLP for 360 frame features.\n",
    "3. Transformer encoder for event tabular features.\n",
    "4. Gated fusion of event + frame embeddings.\n",
    "5. Masked attribute modeling training.\n",
    "6. Save trained model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bd6e93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4123820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['events360_v4.jsonl', 'models']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('/content/drive/MyDrive/MLSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbfc7cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Data path: /content/drive/MyDrive/MLSE/events360_v4.jsonl\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "DATA_PATH = Path('/content/drive/MyDrive/MLSE/events360_v4.jsonl')\n",
    "MODEL_OUT = Path('/content/drive/MyDrive/MLSE/models/event_encoder_mam.pt')\n",
    "MODEL_OUT.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)\n",
    "print('Data path:', DATA_PATH.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ac4e8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def get_flat(d, key, default=None):\n",
    "    return d.get(key, default)\n",
    "\n",
    "\n",
    "def iter_json_objects(fp):\n",
    "    decoder = json.JSONDecoder()\n",
    "    for line in fp:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        idx = 0\n",
    "        while idx < len(line):\n",
    "            obj, end = decoder.raw_decode(line, idx)\n",
    "            yield obj\n",
    "            idx = end\n",
    "            while idx < len(line) and line[idx].isspace():\n",
    "                idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05e3d02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derived EVENT_FEATURES: 72\n"
     ]
    }
   ],
   "source": [
    "# Feature schema (derived from flattened dataset)\n",
    "# We keep categorical/bucketized features and exclude list fields and ids.\n",
    "\n",
    "import json\n",
    "\n",
    "# Fields to exclude (identifiers, lists, raw continuous fields)\n",
    "EXCLUDE_PREFIXES = [\n",
    "    'event_uuid',\n",
    "    'id',\n",
    "    'related_events',\n",
    "    'freeze_frame',\n",
    "    'visible_area',\n",
    "]\n",
    "\n",
    "EXCLUDE_CONTAINS = [\n",
    "    'location',   # raw locations\n",
    "    'end_location',\n",
    "    'angle',\n",
    "    'length',\n",
    "    'statsbomb_xg',\n",
    "]\n",
    "\n",
    "# Include bucketized fields\n",
    "INCLUDE_SUFFIXES = [\n",
    "    'bucket',\n",
    "    'bucket.label',\n",
    "]\n",
    "\n",
    "MASK_TOKEN = '[MASK]'\n",
    "UNK_TOKEN = '[UNK]'\n",
    "\n",
    "# Scan dataset to get flattened keys\n",
    "cols = set()\n",
    "with DATA_PATH.open('r', encoding='utf-8') as f:\n",
    "    for ev in iter_json_objects(f):\n",
    "        for k, v in ev.items():\n",
    "            cols.add(k)\n",
    "\n",
    "# Filter keys\n",
    "EVENT_FEATURES = []\n",
    "for k in sorted(cols):\n",
    "    if any(k.startswith(p) for p in EXCLUDE_PREFIXES):\n",
    "        continue\n",
    "    if any(tok in k for tok in EXCLUDE_CONTAINS) and not any(suf in k for suf in INCLUDE_SUFFIXES):\n",
    "        continue\n",
    "    EVENT_FEATURES.append(k)\n",
    "\n",
    "print('Derived EVENT_FEATURES:', len(EVENT_FEATURES))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62170cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab sizes (sample): [('50_50', 2), ('ball_receipt', 2), ('ball_receipt.outcome.id', 3), ('ball_receipt.outcome.name', 3), ('ball_recovery', 2)]\n"
     ]
    }
   ],
   "source": [
    "# Build vocab per feature\n",
    "feature_vocab = {f: {UNK_TOKEN: 0, MASK_TOKEN: 1} for f in EVENT_FEATURES}\n",
    "\n",
    "with DATA_PATH.open('r', encoding='utf-8') as f:\n",
    "    for ev in iter_json_objects(f):\n",
    "        for feat in EVENT_FEATURES:\n",
    "            val = get_flat(ev, feat, UNK_TOKEN)\n",
    "            # normalize booleans to string\n",
    "            if isinstance(val, bool):\n",
    "                val = str(val)\n",
    "            if val is None:\n",
    "                val = UNK_TOKEN\n",
    "            if val not in feature_vocab[feat]:\n",
    "                feature_vocab[feat][val] = len(feature_vocab[feat])\n",
    "\n",
    "vocab_sizes = {k: len(v) for k, v in feature_vocab.items()}\n",
    "print('Vocab sizes (sample):', list(vocab_sizes.items())[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61a533a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "\n",
    "class EventDataset(Dataset):\n",
    "    def __init__(self, path, feature_vocab):\n",
    "        self.events = []\n",
    "        with path.open('r', encoding='utf-8') as f:\n",
    "            for ev in iter_json_objects(f):\n",
    "                self.events.append(ev)\n",
    "        self.feature_vocab = feature_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.events)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ev = self.events[idx]\n",
    "        # event features as categorical indices\n",
    "        feat_ids = []\n",
    "        for feat in EVENT_FEATURES:\n",
    "            val = get_flat(ev, feat, UNK_TOKEN)\n",
    "            if isinstance(val, bool):\n",
    "                val = str(val)\n",
    "            if val is None:\n",
    "                val = UNK_TOKEN\n",
    "            feat_ids.append(self.feature_vocab[feat].get(val, 0))\n",
    "\n",
    "        # frame features (numeric)\n",
    "        frame = ev.get('frame_features')\n",
    "        # If not already precomputed, fall back to zeros\n",
    "        if not isinstance(frame, dict):\n",
    "            frame_vec = [0.0] * len([])\n",
    "        else:\n",
    "            frame_vec = [float(frame.get(k, 0.0)) for k in []]\n",
    "\n",
    "        return torch.tensor(feat_ids, dtype=torch.long), torch.tensor(frame_vec, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2273cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model components\n",
    "\n",
    "class PlayerMLP(nn.Module):\n",
    "    def __init__(self, in_dim=6, hidden=64, out_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class SetEncoder(nn.Module):\n",
    "    def __init__(self, player_dim=6, hidden=64, out_dim=128):\n",
    "        super().__init__()\n",
    "        self.player_mlp = PlayerMLP(in_dim=player_dim, hidden=hidden, out_dim=out_dim)\n",
    "\n",
    "    def forward(self, freeze_frames, actor_locs, device):\n",
    "        batch_embeds = []\n",
    "        for ff, (ax, ay) in zip(freeze_frames, actor_locs):\n",
    "            # handle empty lists/arrays/tensors\n",
    "            if ff is None or (hasattr(ff, '__len__') and len(ff) == 0):\n",
    "                batch_embeds.append(torch.zeros(128, device=device))\n",
    "                continue\n",
    "            per_player = []\n",
    "            for p in ff:\n",
    "                loc = p.get('location')\n",
    "                if loc is None or len(loc) < 2:\n",
    "                    continue\n",
    "                dx = float(loc[0]) - ax\n",
    "                dy = float(loc[1]) - ay\n",
    "                dist = math.sqrt(dx*dx + dy*dy)\n",
    "                angle = math.atan2(dy, dx)\n",
    "                is_teammate = 1.0 if p.get('teammate', False) else 0.0\n",
    "                is_keeper = 1.0 if p.get('keeper', False) else 0.0\n",
    "                vec = torch.tensor([dx, dy, dist, angle, is_teammate, is_keeper], device=device)\n",
    "                per_player.append(vec)\n",
    "            if not per_player:\n",
    "                batch_embeds.append(torch.zeros(128, device=device))\n",
    "                continue\n",
    "            players = torch.stack(per_player, dim=0)\n",
    "            emb = self.player_mlp(players).mean(dim=0)\n",
    "            batch_embeds.append(emb)\n",
    "        return torch.stack(batch_embeds, dim=0)\n",
    "\n",
    "\n",
    "class EventTransformer(nn.Module):\n",
    "    def __init__(self, vocab_sizes, d_model=128, nhead=4, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.features = list(vocab_sizes.keys())\n",
    "        # ModuleDict keys cannot include dots; use stable safe keys\n",
    "        self.safe_names = [f\"f{i}\" for i in range(len(self.features))]\n",
    "        self.name_map = dict(zip(self.features, self.safe_names))\n",
    "        self.value_embeds = nn.ModuleDict({\n",
    "            self.name_map[f]: nn.Embedding(vocab_sizes[f], d_model) for f in self.features\n",
    "        })\n",
    "        self.feature_embeds = nn.Embedding(len(self.features), d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, feat_ids):\n",
    "        B, F = feat_ids.shape\n",
    "        tokens = []\n",
    "        for i, f in enumerate(self.features):\n",
    "            v = self.value_embeds[self.name_map[f]](feat_ids[:, i])\n",
    "            f_emb = self.feature_embeds(torch.tensor(i, device=feat_ids.device))\n",
    "            tokens.append(v + f_emb)\n",
    "        x = torch.stack(tokens, dim=1)\n",
    "        h = self.encoder(x)\n",
    "        z_event = h.mean(dim=1)\n",
    "        return z_event, h\n",
    "\n",
    "\n",
    "class EventEncoder(nn.Module):\n",
    "    def __init__(self, vocab_sizes):\n",
    "        super().__init__()\n",
    "        self.event_encoder = EventTransformer(vocab_sizes)\n",
    "        self.frame_encoder = SetEncoder()\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(128 * 2, 128),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, feat_ids, freeze_frames, actor_locs, device):\n",
    "        z_event, h_tokens = self.event_encoder(feat_ids)\n",
    "        z_frame = self.frame_encoder(freeze_frames, actor_locs, device)\n",
    "        g = self.gate(torch.cat([z_event, z_frame], dim=-1))\n",
    "        z = g * z_event + (1 - g) * z_frame\n",
    "        return z, h_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "432cc445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masked Attribute Modeling\n",
    "\n",
    "class MAMHead(nn.Module):\n",
    "    def __init__(self, vocab_sizes):\n",
    "        super().__init__()\n",
    "        self.features = list(vocab_sizes.keys())\n",
    "        self.safe_names = [f\"f{i}\" for i in range(len(self.features))]\n",
    "        self.name_map = dict(zip(self.features, self.safe_names))\n",
    "        self.heads = nn.ModuleDict({\n",
    "            self.name_map[f]: nn.Linear(128, vocab_sizes[f]) for f in self.features\n",
    "        })\n",
    "\n",
    "    def forward(self, token_reprs):\n",
    "        outs = {}\n",
    "        for i, f in enumerate(self.features):\n",
    "            outs[f] = self.heads[self.name_map[f]](token_reprs[:, i, :])\n",
    "        return outs\n",
    "\n",
    "\n",
    "def mask_inputs(feat_ids, mask_prob=0.15, vocab_sizes=None):\n",
    "    B, F = feat_ids.shape\n",
    "    labels = feat_ids.clone()\n",
    "    masked = feat_ids.clone()\n",
    "\n",
    "    for i in range(B):\n",
    "        for j in range(F):\n",
    "            if random.random() < mask_prob:\n",
    "                rand = random.random()\n",
    "                if rand < 0.8:\n",
    "                    masked[i, j] = 1  # MASK token index\n",
    "                elif rand < 0.9 and vocab_sizes is not None:\n",
    "                    vsize = vocab_sizes[j]\n",
    "                    masked[i, j] = random.randint(0, vsize - 1)\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                labels[i, j] = -100\n",
    "    return masked, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "166804d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.8700\n",
      "Epoch 2 loss: 0.6477\n",
      "Epoch 3 loss: 0.6143\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "dataset = EventDataset(DATA_PATH, feature_vocab)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    feat_ids = torch.stack([b[0] for b in batch], dim=0)\n",
    "    freeze_frames = [b[1] if len(b) > 1 else [] for b in batch]\n",
    "    actor_locs = [b[2] if len(b) > 2 else (0.0, 0.0) for b in batch]\n",
    "    return feat_ids, freeze_frames, actor_locs\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=256, shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "model = EventEncoder(vocab_sizes).to(device)\n",
    "head = MAMHead(vocab_sizes).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(list(model.parameters()) + list(head.parameters()), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "feature_list = list(vocab_sizes.keys())\n",
    "feature_vocab_sizes = [vocab_sizes[f] for f in feature_list]\n",
    "\n",
    "model.train()\n",
    "head.train()\n",
    "\n",
    "for epoch in range(3):\n",
    "    total_loss = 0.0\n",
    "    for feat_ids, freeze_frames, actor_locs in loader:\n",
    "        feat_ids = feat_ids.to(device)\n",
    "\n",
    "        masked, labels = mask_inputs(feat_ids, mask_prob=0.15, vocab_sizes=feature_vocab_sizes)\n",
    "        masked = masked.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        _, token_reprs = model(masked, freeze_frames, actor_locs, device)\n",
    "        logits = head(token_reprs)\n",
    "\n",
    "        loss = 0.0\n",
    "        for i, f in enumerate(feature_list):\n",
    "            loss = loss + criterion(logits[f], labels[:, i])\n",
    "        loss = loss / len(feature_list)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} loss: {total_loss/len(loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ccb4e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to /content/drive/MyDrive/MLSE/models/event_encoder_mam.pt\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "\n",
    "state = {\n",
    "    'event_encoder': model.state_dict(),\n",
    "    'mam_head': head.state_dict(),\n",
    "    'feature_vocab': feature_vocab,\n",
    "}\n",
    "\n",
    "torch.save(state, MODEL_OUT)\n",
    "print('Saved model to', MODEL_OUT.resolve())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
